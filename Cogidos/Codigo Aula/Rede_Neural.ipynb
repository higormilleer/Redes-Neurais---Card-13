{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>159.0000</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>277.00000</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.74</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>124.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9456.00</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius_mean   texture_mean   perimeter_mean   area_mean  \\\n",
       "0           17.99          10.38           122.80      1001.0   \n",
       "1           20.57          17.77           132.90      1326.0   \n",
       "2           19.69          21.25           130.00      1203.0   \n",
       "3           11.42          20.38            77.58       386.1   \n",
       "4           20.29          14.34           135.10      1297.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564         21.56          22.39           142.00      1479.0   \n",
       "565         20.13          28.25           131.20      1261.0   \n",
       "566         16.60          28.08           108.30       858.1   \n",
       "567         20.60          29.33           140.10      1265.0   \n",
       "568          7.76          24.54            47.92       181.0   \n",
       "\n",
       "      smoothness_mean   compactness_mean   concavity_mean  \\\n",
       "0             0.11840            0.27760          0.30010   \n",
       "1             0.08474            0.07864          0.08690   \n",
       "2             0.10960            0.15990          0.19740   \n",
       "3             0.14250            0.28390          0.24140   \n",
       "4             0.10030            0.13280        198.00000   \n",
       "..                ...                ...              ...   \n",
       "564         111.00000            0.11590          0.24390   \n",
       "565           0.09780            0.10340        144.00000   \n",
       "566           0.08455            0.10230          0.09251   \n",
       "567           0.11780          277.00000          0.35140   \n",
       "568           0.05263            0.04362          0.00000   \n",
       "\n",
       "     concave_points_mean   symmetry_mean   fractal_dimension_mean  ...  \\\n",
       "0                0.14710          0.2419                  0.07871  ...   \n",
       "1                0.07017          0.1812                  0.05667  ...   \n",
       "2                0.12790          0.2069                  0.05999  ...   \n",
       "3                0.10520          0.2597                  0.09744  ...   \n",
       "4                0.10430          0.1809                  0.05883  ...   \n",
       "..                   ...             ...                      ...  ...   \n",
       "564              0.13890          0.1726                  0.05623  ...   \n",
       "565              0.09791          0.1752                  0.05533  ...   \n",
       "566              0.05302        159.0000                  0.05648  ...   \n",
       "567            152.00000          0.2397                  0.07016  ...   \n",
       "568              0.00000          0.1587                  0.05884  ...   \n",
       "\n",
       "      radius_worst   texture_worst   perimeter_worst   area_worst  \\\n",
       "0            25.38           17.33            184.60       2019.0   \n",
       "1            24.99           23.41            158.80       1956.0   \n",
       "2            23.57           25.53            152.50       1709.0   \n",
       "3            14.91           26.50             98.87        567.7   \n",
       "4            22.54           16.67            152.20       1575.0   \n",
       "..             ...             ...               ...          ...   \n",
       "564          25.45           26.40            166.10       2027.0   \n",
       "565          23.69           38.25            155.00       1731.0   \n",
       "566          18.98           34.12            126.70       1124.0   \n",
       "567          25.74           39.42            184.60       1821.0   \n",
       "568        9456.00           30.37             59.16        268.6   \n",
       "\n",
       "      smoothness_worst   compactness_worst   concavity_worst  \\\n",
       "0              0.16220             0.66560            0.7119   \n",
       "1              0.12380             0.18660            0.2416   \n",
       "2              0.14440             0.42450            0.4504   \n",
       "3              0.20980             0.86630            0.6869   \n",
       "4              0.13740           205.00000            0.4000   \n",
       "..                 ...                 ...               ...   \n",
       "564          141.00000             0.21130            0.4107   \n",
       "565            0.11660             0.19220            0.3215   \n",
       "566            0.11390             0.30940            0.3403   \n",
       "567          165.00000             0.86810            0.9387   \n",
       "568            0.08996             0.06444            0.0000   \n",
       "\n",
       "      concave_points_worst   symmetry_worst   fractal_dimension_worst  \n",
       "0                   0.2654           0.4601                   0.11890  \n",
       "1                 186.0000         275.0000                   0.08902  \n",
       "2                 243.0000           0.3613                   0.08758  \n",
       "3                   0.2575           0.6638                 173.00000  \n",
       "4                   0.1625           0.2364                   0.07678  \n",
       "..                     ...              ...                       ...  \n",
       "564                 0.2216         206.0000                   0.07115  \n",
       "565                 0.1628           0.2572                   0.06637  \n",
       "566                 0.1418           0.2218                   0.07820  \n",
       "567               265.0000           0.4087                 124.00000  \n",
       "568                 0.0000           0.2871                   0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base de dados de entrada\n",
    "x = pd.read_csv(\"entradas_breast.csv\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base da dados da saida\n",
    "y = pd.read_csv(\"saidas_breast.csv\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#biblioteca responsavel pelo treiamento da maquina\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidindo as varivaies q iremos utilizar com o x e y (treinamento e teste), com a porcentagem de teste pre definida\n",
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(x,y,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (426, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treinamento.shape, y_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143, 30), (143, 1))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste.shape, y_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(30 + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_neural = Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(30,)),  # usando 'shape' ao invés de 'input_shape' por conta de um erro\n",
    "    tf.keras.layers.Dense(units=16, activation=\"relu\", kernel_initializer=\"random_uniform\"),  # neurônios na camada oculta\n",
    "    tf.keras.layers.Dense(units=16, activation=\"relu\",kernel_initializer=\"random_uniform\"),#mais uma camada oculta\n",
    "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")  # uma saída, portanto sigmoid\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 16)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30*16, 496-480 #foi adcionado a undiade de BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rede_neural.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - binary_accuracy: 0.9241 - loss: 0.1475\n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - binary_accuracy: 0.9577 - loss: 0.1036\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - binary_accuracy: 0.9621 - loss: 0.1214\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - binary_accuracy: 0.9406 - loss: 0.1226\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - binary_accuracy: 0.9377 - loss: 0.1400\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - binary_accuracy: 0.9439 - loss: 0.1336\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - binary_accuracy: 0.9722 - loss: 0.0826\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - binary_accuracy: 0.9614 - loss: 0.1233\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - binary_accuracy: 0.9277 - loss: 0.1542\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - binary_accuracy: 0.9437 - loss: 0.1383\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.9384 - loss: 0.1139\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - binary_accuracy: 0.9636 - loss: 0.1305\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8881 - loss: 0.1954\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - binary_accuracy: 0.9426 - loss: 0.1373\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - binary_accuracy: 0.9297 - loss: 0.1510\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - binary_accuracy: 0.9495 - loss: 0.1186\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - binary_accuracy: 0.9480 - loss: 0.1334\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - binary_accuracy: 0.9338 - loss: 0.1237\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - binary_accuracy: 0.9588 - loss: 0.1052\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - binary_accuracy: 0.9546 - loss: 0.1157\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - binary_accuracy: 0.9331 - loss: 0.1310\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - binary_accuracy: 0.9314 - loss: 0.1234\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.9471 - loss: 0.1075\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - binary_accuracy: 0.9638 - loss: 0.0943\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.9317 - loss: 0.1237\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - binary_accuracy: 0.9587 - loss: 0.1009\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - binary_accuracy: 0.9533 - loss: 0.1053\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - binary_accuracy: 0.9516 - loss: 0.1266\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - binary_accuracy: 0.9401 - loss: 0.1176\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - binary_accuracy: 0.9345 - loss: 0.1482\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - binary_accuracy: 0.9264 - loss: 0.1336\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - binary_accuracy: 0.9516 - loss: 0.0927\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - binary_accuracy: 0.9437 - loss: 0.1244\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - binary_accuracy: 0.9686 - loss: 0.0887\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - binary_accuracy: 0.9507 - loss: 0.1070\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - binary_accuracy: 0.9414 - loss: 0.1285\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - binary_accuracy: 0.9360 - loss: 0.1307\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - binary_accuracy: 0.9548 - loss: 0.1079\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - binary_accuracy: 0.9492 - loss: 0.1344\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - binary_accuracy: 0.9589 - loss: 0.1013\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - binary_accuracy: 0.9351 - loss: 0.1478\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - binary_accuracy: 0.9444 - loss: 0.1193\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - binary_accuracy: 0.9306 - loss: 0.1365\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - binary_accuracy: 0.9520 - loss: 0.1105\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - binary_accuracy: 0.9486 - loss: 0.1106\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - binary_accuracy: 0.9436 - loss: 0.1185\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - binary_accuracy: 0.9237 - loss: 0.1550\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - binary_accuracy: 0.9250 - loss: 0.1447\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - binary_accuracy: 0.9363 - loss: 0.1561\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - binary_accuracy: 0.9350 - loss: 0.1505\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - binary_accuracy: 0.9536 - loss: 0.1027\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - binary_accuracy: 0.9466 - loss: 0.1135\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - binary_accuracy: 0.9462 - loss: 0.1334\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.9462 - loss: 0.1019\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - binary_accuracy: 0.9335 - loss: 0.1239\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - binary_accuracy: 0.9673 - loss: 0.0940\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.9508 - loss: 0.1073\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - binary_accuracy: 0.9501 - loss: 0.0847\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - binary_accuracy: 0.9477 - loss: 0.1084\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - binary_accuracy: 0.9696 - loss: 0.0711\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - binary_accuracy: 0.9518 - loss: 0.0884\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - binary_accuracy: 0.9462 - loss: 0.1507\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - binary_accuracy: 0.9430 - loss: 0.1059\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - binary_accuracy: 0.9508 - loss: 0.1076\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - binary_accuracy: 0.9441 - loss: 0.1110\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - binary_accuracy: 0.9538 - loss: 0.1255\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - binary_accuracy: 0.9580 - loss: 0.0894\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - binary_accuracy: 0.9498 - loss: 0.1060\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - binary_accuracy: 0.9724 - loss: 0.1060\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - binary_accuracy: 0.9406 - loss: 0.1324\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - binary_accuracy: 0.9516 - loss: 0.1022\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - binary_accuracy: 0.9165 - loss: 0.1966\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - binary_accuracy: 0.9645 - loss: 0.0970\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - binary_accuracy: 0.9444 - loss: 0.1204   \n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - binary_accuracy: 0.9456 - loss: 0.1170\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - binary_accuracy: 0.9539 - loss: 0.1012\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - binary_accuracy: 0.9304 - loss: 0.1408\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - binary_accuracy: 0.9449 - loss: 0.0936\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - binary_accuracy: 0.9605 - loss: 0.0930\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - binary_accuracy: 0.9386 - loss: 0.1399\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - binary_accuracy: 0.9514 - loss: 0.1118\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - binary_accuracy: 0.9689 - loss: 0.0666\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - binary_accuracy: 0.9540 - loss: 0.0782\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - binary_accuracy: 0.9199 - loss: 0.1825\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - binary_accuracy: 0.9553 - loss: 0.0969\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - binary_accuracy: 0.9558 - loss: 0.1080\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - binary_accuracy: 0.9668 - loss: 0.0818\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - binary_accuracy: 0.9598 - loss: 0.0899\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - binary_accuracy: 0.9200 - loss: 0.1231\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - binary_accuracy: 0.9559 - loss: 0.0933\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - binary_accuracy: 0.9660 - loss: 0.0829\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - binary_accuracy: 0.9515 - loss: 0.0955\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - binary_accuracy: 0.9459 - loss: 0.1160\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - binary_accuracy: 0.9302 - loss: 0.1399\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - binary_accuracy: 0.9373 - loss: 0.1395\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - binary_accuracy: 0.9543 - loss: 0.1054\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - binary_accuracy: 0.9595 - loss: 0.1011\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - binary_accuracy: 0.9676 - loss: 0.0741\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - binary_accuracy: 0.9416 - loss: 0.1200\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - binary_accuracy: 0.9508 - loss: 0.1233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x304b87d10>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#treinamento da rede neural\n",
    "rede_neural.fit(x_treinamento,y_treinamento, batch_size = 10, epochs = 100) #10 em 10 registros = 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-5.94162755e-02, -2.41037041e-01,  4.10017759e-01,\n",
       "          2.31818501e-02, -2.88539287e-02,  2.43682876e-01,\n",
       "          7.07346648e-02,  2.58070920e-02, -1.40611231e-01,\n",
       "         -3.15300487e-02,  3.05366684e-02,  4.00888100e-02,\n",
       "         -1.08958229e-01,  1.21974804e-01, -5.74833639e-02,\n",
       "         -4.07798961e-02],\n",
       "        [-2.14229394e-02, -3.39873254e-01,  6.11189939e-02,\n",
       "          1.52344946e-02, -2.50563864e-02,  7.02372640e-02,\n",
       "         -1.83062907e-02, -1.80090114e-01,  1.22272698e-02,\n",
       "          2.71001216e-02, -3.35903801e-02,  2.08689980e-02,\n",
       "          1.60273820e-01, -8.16716813e-03, -1.46657992e-02,\n",
       "          2.43042037e-02],\n",
       "        [-1.16716931e-03, -1.52007833e-01,  3.44437599e-01,\n",
       "         -2.92779859e-02,  1.15388855e-02,  2.35734150e-01,\n",
       "          2.38406271e-01, -2.64178693e-01, -3.71466160e-01,\n",
       "         -5.57028968e-03,  4.50014099e-02,  4.39895056e-02,\n",
       "         -3.52991253e-01,  2.82471985e-01,  1.50704896e-03,\n",
       "         -3.03368899e-03],\n",
       "        [-1.07864467e-02,  3.38489190e-03,  4.27380987e-02,\n",
       "         -5.16624488e-02,  1.83100626e-03,  4.88165542e-02,\n",
       "          3.95727046e-02, -7.40702227e-02, -8.56961608e-02,\n",
       "         -5.08271158e-02, -1.65449306e-02,  5.67945018e-02,\n",
       "         -1.02221064e-01,  2.90342364e-02, -1.70382131e-02,\n",
       "         -5.73645998e-03],\n",
       "        [ 3.71420793e-02, -5.81650361e-02, -5.30309081e-02,\n",
       "         -3.94645147e-02, -3.20529491e-02, -3.10432404e-01,\n",
       "         -1.71125174e-01, -1.68549046e-01,  1.81854129e-01,\n",
       "         -5.28755561e-02,  5.23233823e-02,  3.90380263e-01,\n",
       "          3.61889720e-01,  1.95751369e-01,  6.25001499e-03,\n",
       "         -4.29093651e-02],\n",
       "        [ 3.25497650e-02, -5.50475568e-02,  7.87280500e-02,\n",
       "          8.20127243e-05, -3.43848392e-03, -2.91817099e-01,\n",
       "         -4.81412560e-03,  1.08291492e-01, -1.09756179e-01,\n",
       "          1.64278653e-02, -1.26594249e-02,  1.01332748e-02,\n",
       "          2.13945985e-01,  9.85473394e-03, -6.54030815e-02,\n",
       "         -4.42950465e-02],\n",
       "        [ 6.35457039e-03,  9.55413748e-03,  1.51648605e-03,\n",
       "         -1.48569411e-02,  3.54691595e-03,  2.02304661e-01,\n",
       "         -2.29668356e-02, -2.43840203e-01,  1.56804696e-01,\n",
       "          1.63128413e-02,  3.18645500e-03, -1.17375232e-01,\n",
       "         -3.16142887e-01, -3.54645461e-01, -5.18809222e-02,\n",
       "         -4.17534299e-02],\n",
       "        [-8.73519201e-03,  1.39360037e-02,  1.84770212e-01,\n",
       "         -2.76197563e-03, -4.18810137e-02, -2.50402540e-02,\n",
       "          8.64172801e-02,  4.80072051e-02, -1.12957709e-01,\n",
       "          3.80460918e-02, -4.76820320e-02,  1.27775818e-01,\n",
       "         -1.63453937e-01,  1.37439340e-01,  5.17906039e-04,\n",
       "         -4.42183875e-02],\n",
       "        [ 1.14468783e-02, -1.29842013e-01, -5.63862063e-02,\n",
       "          2.12825276e-02, -2.49086022e-02,  7.52662495e-03,\n",
       "          1.03288576e-01,  8.96481797e-02,  6.42986223e-02,\n",
       "         -4.89982180e-02, -1.12836463e-02,  1.92609087e-01,\n",
       "         -1.77578956e-01,  1.78254604e-01,  4.26569246e-02,\n",
       "          3.12761329e-02],\n",
       "        [ 2.76684631e-02,  4.75266576e-01,  4.34868515e-01,\n",
       "         -9.87564027e-03,  5.49484417e-03,  3.14107984e-01,\n",
       "         -1.40147880e-01, -1.63425063e-03, -1.80730462e-01,\n",
       "         -4.40698722e-03,  6.74736500e-02,  3.02873135e-01,\n",
       "          6.70839325e-02, -4.14791048e-01,  2.10699365e-02,\n",
       "         -1.38722183e-02],\n",
       "        [-3.46333869e-02,  5.31810895e-02,  7.36796111e-02,\n",
       "         -2.71535795e-02,  1.34650730e-02, -1.05291046e-01,\n",
       "          1.43548727e-01, -5.17235957e-02,  2.03221831e-02,\n",
       "         -2.75576897e-02,  1.76973827e-02,  1.85578525e-01,\n",
       "         -2.05968898e-02, -6.61800131e-02,  2.42744964e-02,\n",
       "         -2.70695258e-02],\n",
       "        [-1.27716921e-02,  4.19002138e-02, -1.30452646e-03,\n",
       "          1.36255426e-02, -3.86902466e-02, -3.13847139e-02,\n",
       "         -2.70474646e-02, -1.54569792e-02,  2.89501809e-03,\n",
       "          5.25259692e-03, -1.91967171e-02,  5.75458407e-02,\n",
       "          2.70176306e-03,  5.21276593e-02, -1.79874077e-02,\n",
       "          3.59119521e-03],\n",
       "        [-2.35870425e-02, -4.29918058e-02,  8.97165481e-03,\n",
       "         -7.16686063e-03, -3.23998928e-02,  1.66118070e-02,\n",
       "         -1.79884825e-02,  1.20549845e-02, -2.72829621e-03,\n",
       "         -1.79033279e-02, -1.43568069e-02, -7.08113611e-02,\n",
       "          1.62416194e-02,  1.20984379e-03, -2.55616028e-02,\n",
       "         -9.33184568e-03],\n",
       "        [ 1.28692746e-01,  1.40443891e-01, -1.21245757e-01,\n",
       "         -5.82277663e-02, -4.78468649e-02,  2.44464707e-02,\n",
       "         -2.87122846e-01,  1.18877865e-01,  7.32420236e-02,\n",
       "          8.48349258e-02,  8.90261829e-02,  1.13993160e-01,\n",
       "          1.30794302e-01, -2.48479888e-01,  5.52477082e-03,\n",
       "         -1.68920103e-02],\n",
       "        [-2.81820055e-02, -6.87397063e-01, -9.47160795e-02,\n",
       "          4.06048149e-02, -2.98670661e-02,  1.00879975e-01,\n",
       "         -5.82264215e-02, -2.62116879e-01,  2.26074249e-01,\n",
       "         -3.38075892e-03, -1.73402298e-02, -1.20269090e-01,\n",
       "          2.60219067e-01,  4.20998931e-02,  1.70545019e-02,\n",
       "          7.59796146e-03],\n",
       "        [-1.79170966e-02, -4.74821746e-01, -1.11825988e-01,\n",
       "          2.38726381e-02, -4.52624932e-02, -2.39991546e-01,\n",
       "          4.27797213e-02,  8.99381936e-03,  1.48678094e-01,\n",
       "          3.76168042e-02, -3.35047506e-02, -1.63887382e-01,\n",
       "          2.82289982e-01,  5.50590515e-01,  1.33617343e-02,\n",
       "          1.74849238e-02],\n",
       "        [-4.36381288e-02,  2.48397306e-01,  1.75639093e-01,\n",
       "          1.94465183e-02,  3.56113203e-02, -5.02444625e-01,\n",
       "          4.12506238e-02, -1.07383177e-01, -1.15858071e-01,\n",
       "         -3.01002953e-02, -1.86832920e-02,  4.22854096e-01,\n",
       "          2.53906280e-01,  3.18928361e-01,  1.49241369e-02,\n",
       "         -3.90634611e-02],\n",
       "        [ 3.37978452e-02,  2.00312749e-01,  4.67666835e-01,\n",
       "         -2.49827243e-02, -3.55838314e-02, -2.04706058e-01,\n",
       "          1.83403850e-01, -1.03402331e-01, -4.48039830e-01,\n",
       "         -5.38475476e-02,  3.60327214e-02, -2.30250105e-01,\n",
       "          2.46203527e-01,  3.92895564e-03, -3.84867378e-02,\n",
       "         -2.23888941e-02],\n",
       "        [-5.60577214e-03,  3.73267233e-01,  5.01320660e-01,\n",
       "         -4.77879643e-02, -2.51418483e-02,  6.38883770e-01,\n",
       "         -1.71070114e-01,  3.29000093e-02,  2.85523623e-01,\n",
       "         -5.70186004e-02, -3.72084267e-02,  5.47010839e-01,\n",
       "          3.13987494e-01, -8.43910575e-01, -4.97648828e-02,\n",
       "         -3.76095362e-02],\n",
       "        [-7.58084282e-02,  2.93767899e-01, -7.41563737e-01,\n",
       "         -4.28637639e-02, -1.38090737e-02,  7.17214048e-02,\n",
       "         -3.58680904e-01,  1.77681580e-01,  9.58531320e-01,\n",
       "         -4.94511724e-02,  2.28953809e-02, -2.29268134e-01,\n",
       "          9.83330011e-01, -7.70307422e-01,  2.11256426e-02,\n",
       "         -4.72533479e-02],\n",
       "        [ 1.23591274e-02, -2.41610840e-01,  2.91792452e-01,\n",
       "         -2.88146865e-02, -3.92857902e-02,  2.16660574e-01,\n",
       "          2.80386861e-03, -4.09836620e-02, -1.48209766e-01,\n",
       "         -2.82573327e-02, -1.26030594e-02,  7.42987264e-03,\n",
       "         -8.31082836e-02,  7.96363056e-02,  2.05608308e-02,\n",
       "          1.87769290e-02],\n",
       "        [-6.64062575e-02, -3.59383702e-01, -2.42128536e-01,\n",
       "         -2.67351866e-02, -1.83220990e-02, -1.44805565e-01,\n",
       "         -2.53266394e-01, -1.56533673e-01,  4.67609912e-01,\n",
       "          1.74442548e-02, -2.49293931e-02, -1.61711439e-01,\n",
       "          5.57355881e-01, -2.22874492e-01, -5.79211414e-02,\n",
       "          1.86083000e-02],\n",
       "        [ 2.16685683e-02, -1.34612411e-01,  2.01986432e-01,\n",
       "         -5.77885993e-02,  3.62356417e-02,  1.48149803e-01,\n",
       "          9.32460949e-02, -2.16955274e-01, -2.46069759e-01,\n",
       "         -1.16531074e-03, -5.02581941e-03, -6.98893443e-02,\n",
       "         -1.19347990e-01,  1.39510438e-01,  1.24870036e-02,\n",
       "          2.72149853e-02],\n",
       "        [-3.32993269e-02, -1.20613659e-02, -9.55299810e-02,\n",
       "         -4.56367061e-02, -2.27125287e-02, -1.09670013e-01,\n",
       "         -4.30784151e-02, -4.82180044e-02,  1.54788181e-01,\n",
       "         -4.00926406e-03, -1.87743139e-02,  2.69850437e-02,\n",
       "          9.46308821e-02, -1.01344347e-01, -1.18617015e-02,\n",
       "         -3.66676413e-02],\n",
       "        [-2.41440106e-02, -2.55318314e-01, -7.67255053e-02,\n",
       "          3.87746952e-02,  4.10029553e-02,  1.73292775e-02,\n",
       "          2.65934139e-01,  1.22277729e-01, -1.81701675e-03,\n",
       "          3.54311801e-02,  5.53280711e-02, -3.94291997e-01,\n",
       "          3.61649357e-02, -1.90730035e-01, -3.08183748e-02,\n",
       "          1.63286794e-02],\n",
       "        [-6.86845034e-02,  8.93923268e-02, -4.90281396e-02,\n",
       "         -1.29087837e-02,  4.27368768e-02,  8.30331892e-02,\n",
       "         -1.03365108e-01,  2.70593852e-01,  5.86184189e-02,\n",
       "         -6.39592484e-02,  2.76174992e-02,  1.38287038e-01,\n",
       "         -2.42486194e-01,  2.17080284e-02,  2.18031146e-02,\n",
       "         -3.35664465e-03],\n",
       "        [ 3.65302130e-03, -9.09697264e-02,  1.03000969e-01,\n",
       "         -4.55117300e-02, -9.10598040e-03, -1.74184330e-02,\n",
       "         -5.19323312e-02, -4.89291437e-02,  2.83569265e-02,\n",
       "          4.26792875e-02,  2.37229243e-02, -2.00514674e-01,\n",
       "         -3.21127146e-01, -1.82151869e-01,  1.32830245e-02,\n",
       "         -4.75268699e-02],\n",
       "        [ 2.47219810e-03,  1.95215568e-01, -1.60530005e-02,\n",
       "         -1.75979466e-03,  1.90504640e-03, -4.16340865e-02,\n",
       "         -4.38372530e-02,  1.49169445e-01,  1.17723472e-01,\n",
       "         -3.97888653e-05, -4.35233153e-02,  6.73750579e-01,\n",
       "         -4.41858619e-01,  6.11511357e-02,  3.90678123e-02,\n",
       "         -4.04720977e-02],\n",
       "        [-2.27713268e-02, -9.73010883e-02,  9.88838747e-02,\n",
       "          2.84316391e-02, -1.30283237e-02, -1.79655045e-01,\n",
       "          1.73010468e-01,  1.75387368e-01, -7.02877576e-03,\n",
       "         -5.61456606e-02,  9.74956900e-03, -5.47601581e-02,\n",
       "         -3.02412305e-02, -1.18462034e-02, -5.15607744e-02,\n",
       "         -3.35234553e-02],\n",
       "        [-3.03656030e-02, -2.80533582e-01, -3.36198777e-01,\n",
       "          8.60484596e-03, -2.01147441e-02, -6.74708858e-02,\n",
       "         -1.65177122e-01,  1.96003363e-01,  5.29763103e-01,\n",
       "          1.53581146e-02,  1.75232347e-02, -1.56649128e-01,\n",
       "          5.58006763e-01, -2.19786793e-01, -2.24957452e-03,\n",
       "         -2.07843278e-02]], dtype=float32),\n",
       " array([-0.02101141, -0.438342  ,  0.783435  , -0.0097425 ,  0.        ,\n",
       "         0.49810418,  0.51391405, -0.4065961 , -0.7939291 , -0.00526106,\n",
       "         0.00967812,  0.05498518, -0.6901225 ,  0.59445816, -0.0109881 ,\n",
       "        -0.00260053], dtype=float32)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos0 = rede_neural.layers[0].get_weights()\n",
    "pesos0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-9.40175131e-02,  1.30913794e-01, -6.56347871e-02,\n",
       "         -3.78230214e-02,  4.78865318e-02,  8.73057842e-02,\n",
       "         -5.72309978e-02, -1.24288633e-01, -2.91599873e-02,\n",
       "         -2.99566127e-02, -1.13683417e-02, -3.67423557e-02,\n",
       "          6.62159845e-02,  4.58570868e-02,  1.12217732e-01,\n",
       "         -9.04446542e-02],\n",
       "        [ 4.68435064e-02, -1.03349835e-02,  2.04988066e-02,\n",
       "         -5.29845953e-02, -1.25689119e-01, -1.00225545e-01,\n",
       "          5.66574223e-02,  8.84450972e-02, -1.18257096e-02,\n",
       "         -4.03004438e-02, -2.06597298e-01, -8.32374394e-02,\n",
       "         -1.18280262e-01, -1.28291979e-01, -6.88691437e-02,\n",
       "          9.45350006e-02],\n",
       "        [-3.66697907e-02,  3.65411676e-02,  8.74900594e-02,\n",
       "          1.26242554e-02, -1.47031695e-01,  4.58484665e-02,\n",
       "          3.21989357e-02, -1.07704215e-01,  1.27308533e-01,\n",
       "          9.93575901e-03, -1.57276762e-03,  1.01430877e-03,\n",
       "          1.18771799e-01,  9.00309533e-04, -3.75058353e-02,\n",
       "         -8.90645534e-02],\n",
       "        [ 3.71780917e-02,  4.95535135e-02, -2.61468627e-02,\n",
       "          1.28676835e-02,  1.22000044e-02,  2.80927424e-03,\n",
       "          2.59133223e-02, -5.81630878e-03,  2.84019690e-02,\n",
       "         -2.36989707e-02, -5.15355766e-02,  9.45437234e-03,\n",
       "         -4.10885327e-02, -8.71762447e-03,  5.27385902e-03,\n",
       "         -3.87976803e-02],\n",
       "        [-4.72751856e-02,  4.61621024e-02,  4.01583426e-02,\n",
       "          3.11674140e-02,  4.22257520e-02, -4.96319197e-02,\n",
       "         -3.52697447e-03,  1.55188702e-02,  2.30435170e-02,\n",
       "         -4.19125184e-02, -3.58535759e-02,  1.43648311e-03,\n",
       "          3.73909958e-02,  3.32170986e-02,  3.48030590e-02,\n",
       "          4.48115729e-02],\n",
       "        [-2.23271269e-02,  2.17207540e-02, -2.55221706e-02,\n",
       "          1.28632057e-02, -2.25482113e-03,  9.96851772e-02,\n",
       "          1.61964307e-03,  1.15910284e-01,  2.44997486e-01,\n",
       "          3.08238249e-02,  2.77233213e-01,  5.25563024e-02,\n",
       "          1.22489668e-01,  9.03630406e-02,  3.09779644e-02,\n",
       "          1.45875081e-01],\n",
       "        [ 4.19503485e-04,  2.55028661e-02,  4.80192825e-02,\n",
       "          1.06030973e-02, -3.79881822e-02,  4.98199202e-02,\n",
       "         -1.02276299e-02,  2.90235057e-02, -4.17710990e-02,\n",
       "          4.80715185e-02, -3.99747156e-02,  3.50669213e-02,\n",
       "          1.11227669e-01, -2.66601960e-03, -9.09550209e-03,\n",
       "         -7.24087879e-02],\n",
       "        [ 1.38116211e-01, -1.17889745e-02, -9.13070608e-03,\n",
       "         -5.20396000e-03, -4.41810824e-02,  1.66113526e-02,\n",
       "          3.88101675e-02,  5.22173233e-02,  7.06987530e-02,\n",
       "          5.76182734e-03,  9.87966433e-02, -1.28322989e-02,\n",
       "         -1.71402358e-02,  3.48697975e-02,  2.71711927e-02,\n",
       "         -8.96482691e-02],\n",
       "        [ 8.55657607e-02, -1.18560251e-02, -5.96904429e-03,\n",
       "          9.24035981e-02, -7.27079883e-02, -2.28696074e-02,\n",
       "          9.02482197e-02,  3.64661366e-02, -1.29336104e-01,\n",
       "         -1.10780001e-02, -3.38701934e-01, -1.00390119e-02,\n",
       "         -7.20202774e-02,  3.05235060e-03, -2.97104996e-02,\n",
       "          1.13468140e-01],\n",
       "        [-9.60437879e-02,  7.11961985e-02, -3.66971269e-02,\n",
       "         -4.17461433e-02, -1.04586035e-03,  6.55741766e-02,\n",
       "         -8.14465284e-02, -1.98632944e-02,  3.03724017e-02,\n",
       "         -5.23770638e-02,  3.91032137e-02, -1.49126649e-02,\n",
       "         -5.41461147e-02, -1.37507897e-02,  1.14507768e-02,\n",
       "         -7.42524937e-02],\n",
       "        [-1.14451647e-01,  7.22012371e-02, -6.40753806e-02,\n",
       "         -2.23360118e-03,  6.69101719e-03,  1.13913596e-01,\n",
       "         -1.00505792e-01, -9.56274867e-02, -3.46138445e-03,\n",
       "          1.65317226e-02, -2.18659192e-02,  4.98264357e-02,\n",
       "         -2.20260508e-02,  1.06370449e-01,  8.07460099e-02,\n",
       "         -1.12052053e-01],\n",
       "        [ 6.95936084e-02,  1.93159301e-02,  2.96884999e-02,\n",
       "         -9.70529094e-02, -1.69586223e-02,  1.65553875e-02,\n",
       "         -1.04424044e-01,  4.67151888e-02,  7.86570087e-02,\n",
       "         -5.84384836e-02, -1.51639488e-02,  2.34563966e-04,\n",
       "          3.72453518e-02,  8.00678041e-03,  3.61586083e-03,\n",
       "          1.09170996e-01],\n",
       "        [-8.37067291e-02, -8.42003617e-03,  9.46354643e-02,\n",
       "          4.91180494e-02, -1.99620165e-02,  1.51632251e-02,\n",
       "          5.54050282e-02,  2.55162269e-02, -1.93019524e-01,\n",
       "          6.63430616e-02,  1.80285983e-02, -1.06992759e-02,\n",
       "         -2.80941486e-01, -3.07342783e-03, -2.89881323e-02,\n",
       "         -7.09606260e-02],\n",
       "        [-1.94624841e-01,  6.04528561e-02, -1.31045982e-01,\n",
       "          4.55829538e-02, -1.25431921e-02,  7.54705518e-02,\n",
       "          3.59474905e-02, -5.81405535e-02,  5.42715602e-02,\n",
       "          4.19862680e-02,  7.02121630e-02,  5.79098472e-03,\n",
       "          2.09012982e-02,  3.20386551e-02, -3.73317307e-04,\n",
       "         -2.76164383e-01],\n",
       "        [-4.35440801e-02, -1.11685637e-02,  1.06756939e-02,\n",
       "         -3.99964489e-02, -1.02892229e-02, -2.07108371e-02,\n",
       "          2.98229605e-02, -1.93812307e-02,  2.38107219e-02,\n",
       "         -3.47131640e-02, -2.89840344e-03,  1.41199753e-02,\n",
       "         -1.90277994e-02,  2.25163326e-02, -4.29318808e-02,\n",
       "          5.19333929e-02],\n",
       "        [ 4.44120020e-02,  5.01740538e-03, -4.17230427e-02,\n",
       "         -1.40796369e-03,  2.10523400e-02, -4.16779220e-02,\n",
       "         -3.72796804e-02, -1.94817856e-02,  3.91344540e-03,\n",
       "         -4.02470715e-02,  3.41407508e-02, -4.02223282e-02,\n",
       "         -1.38172880e-02,  4.92395386e-02,  4.49255072e-02,\n",
       "          5.11430390e-03]], dtype=float32),\n",
       " array([-0.67521554,  0.75864065, -0.81538415, -0.64119273, -0.03436776,\n",
       "         0.77967733, -0.62159765, -0.6301541 ,  0.64076066, -0.5802856 ,\n",
       "        -0.04383386,  0.64103496,  0.90538067,  0.72513396,  0.43326166,\n",
       "        -0.6701584 ], dtype=float32)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos1 = rede_neural.layers[1].get_weights()\n",
    "pesos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.40984508],\n",
       "        [ 0.1551447 ],\n",
       "        [-0.17358765],\n",
       "        [-0.25741753],\n",
       "        [ 0.50937253],\n",
       "        [ 0.5053271 ],\n",
       "        [-0.49259505],\n",
       "        [-0.24560806],\n",
       "        [ 0.30268273],\n",
       "        [-0.11852477],\n",
       "        [ 0.13774413],\n",
       "        [ 0.01238967],\n",
       "        [ 0.45709503],\n",
       "        [ 0.17936774],\n",
       "        [ 0.00404047],\n",
       "        [-0.23507743]], dtype=float32),\n",
       " array([0.75934464], dtype=float32)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos2 = rede_neural.layers[2].get_weights()\n",
    "pesos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pesos2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 arrays, um pesos entre a camda de entrada com a oculta, e o peso das unidade de bias que apontam para a camada oculta\n",
    "len(pesos0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "previsoes = rede_neural.predict(x_teste)\n",
    "previsoes = previsoes > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "244  0\n",
       "184  0\n",
       "284  1\n",
       "180  0\n",
       "497  1\n",
       "..  ..\n",
       "186  0\n",
       "45   0\n",
       "161  0\n",
       "369  0\n",
       "225  1\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentual de acerto da rede neural dos registros\n",
    "accuracy_score(y_teste, previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44,  8],\n",
       "       [ 3, 88]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quantidade de registros certos, somando a diagonal para quantidade de acertos\n",
    "confusion_matrix(y_teste,previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - binary_accuracy: 0.9301 - loss: 0.2482 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2541980445384979, 0.9230769276618958]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#valor do erro e o valor do acerto(accuracy)\n",
    "rede_neural.evaluate(x_teste,y_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
